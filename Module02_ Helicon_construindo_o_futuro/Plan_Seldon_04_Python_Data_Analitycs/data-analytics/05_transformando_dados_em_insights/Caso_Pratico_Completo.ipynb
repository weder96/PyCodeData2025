{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a32f2d6",
   "metadata": {
    "id": "3a32f2d6"
   },
   "source": [
    "# Previsão de Churn em Clientes SaaS\n",
    "\n",
    "1. Pré-processamento e tratamento de dados\n",
    "2. Feature Engineering detalhado\n",
    "3. Seleção de variáveis (multicolinearidade, SelectKBest, RFE)\n",
    "4. Divisão treino/teste e validação cruzada\n",
    "5. Treinamento comparativo de modelos: Regressão Logística, Random Forest, XGBoost e SVM\n",
    "6. Avaliação de performance (AUC, F1, precisão, recall)\n",
    "7. Verificação de overfitting/underfitting\n",
    "8. Explainable AI (SHAP) para o modelo final\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3018481",
   "metadata": {
    "id": "d3018481"
   },
   "source": [
    "## 1. Importando bibliotecas necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c236b392",
   "metadata": {
    "id": "c236b392"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, chi2, RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report, RocCurveDisplay\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import shap\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3345bc9c",
   "metadata": {
    "id": "3345bc9c"
   },
   "source": [
    "## 2. Carregando e visualizando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38a04fa",
   "metadata": {
    "id": "b38a04fa"
   },
   "outputs": [],
   "source": [
    "# Carrega a base de dados\n",
    "df = pd.read_csv('/mnt/data/base_churn_saas.csv')\n",
    "print('Dimensões da base:', df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6082b7",
   "metadata": {
    "id": "6e6082b7"
   },
   "source": [
    "## 3. Pré-processamento e tratamento inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc46a6a",
   "metadata": {
    "id": "fdc46a6a"
   },
   "outputs": [],
   "source": [
    "# 3.1 Verificando valores faltantes\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cc4a62",
   "metadata": {
    "id": "65cc4a62"
   },
   "source": [
    "**Insight**: Não há valores faltantes, portanto não será necessário imputação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a967dbdd",
   "metadata": {
    "id": "a967dbdd"
   },
   "outputs": [],
   "source": [
    "# 3.2 Remover colunas irrelevantes\n",
    "df.drop(columns=['id_cliente', 'codigo_cliente', 'constante'], inplace=True)\n",
    "print('Novas dimensões:', df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc733146",
   "metadata": {
    "id": "cc733146"
   },
   "source": [
    "Removemos identificadores e a coluna constante, pois não agregam nenhuma informação preditiva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0636054d",
   "metadata": {
    "id": "0636054d"
   },
   "outputs": [],
   "source": [
    "# 3.3 Convertendo variáveis categóricas para o tipo 'category'\n",
    "categorical_cols = ['plano', 'regiao', 'navegador_usado']\n",
    "for col in categorical_cols:\n",
    "    df[col] = df[col].astype('category')\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78bddf7",
   "metadata": {
    "id": "f78bddf7"
   },
   "source": [
    "Convertidas variáveis categóricas para o tipo adequado para facilitar codificação posterior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c5e0fb",
   "metadata": {
    "id": "e4c5e0fb"
   },
   "source": [
    "## 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d361e61d",
   "metadata": {
    "id": "d361e61d"
   },
   "source": [
    "Vamos criar novas variáveis com base em conhecimento de negócio:\n",
    "- `uso_total`: combinação de frequência de uso e tempo total de login\n",
    "- `dias_sem_login`: cópia de `ultimo_login_dias`\n",
    "- `suporte_freq`: relação entre chamados abertos e tempo de contrato\n",
    "- `satisfacao_baixa`: flag se avaliação de satisfação < 3\n",
    "- `acesso_noturno`: flag se `hora_ultimo_acesso` entre 0 e 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b970f01",
   "metadata": {
    "id": "1b970f01"
   },
   "outputs": [],
   "source": [
    "# 4.1 Criando features derivadas\n",
    "df['uso_total'] = df['frequencia_uso_mensal'] * df['tempo_total_login_horas']\n",
    "df['dias_sem_login'] = df['ultimo_login_dias']\n",
    "df['suporte_freq'] = df['suporte_chamados_abertos'] / (df['tempo_de_contrato_meses'] + 1)\n",
    "df['satisfacao_baixa'] = (df['avaliacao_satisfacao'] < 3).astype(int)\n",
    "df['acesso_noturno'] = df['hora_ultimo_acesso'].apply(lambda x: 1 if x <= 6 else 0)\n",
    "df[['uso_total','suporte_freq','satisfacao_baixa','acesso_noturno']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f776026",
   "metadata": {
    "id": "8f776026"
   },
   "source": [
    "Criamos variáveis que podem capturar comportamentos de risco de churn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cdb19b",
   "metadata": {
    "id": "69cdb19b"
   },
   "source": [
    "## 5. Codificação de variáveis categóricas e escalonamento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264e14d1",
   "metadata": {
    "id": "264e14d1"
   },
   "source": [
    "Vamos separar variáveis numéricas e categóricas para construir um `ColumnTransformer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iFy8Q6L96gIB",
   "metadata": {
    "id": "iFy8Q6L96gIB"
   },
   "outputs": [],
   "source": [
    "# 5.1 Definir X e y\n",
    "X = df.drop('churn', axis=1)               # Cria X retirando a coluna 'churn' do DataFrame df; axis=1 indica remoção de coluna\n",
    "y = df['churn']                            # Cria y contendo apenas a coluna 'churn' (variável-alvo)\n",
    "\n",
    "# Identificar colunas numéricas (tipo inteiro ou float) e categóricas (tipo category)\n",
    "num_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "                                           # select_dtypes seleciona colunas cujo dtype é int64 ou float64\n",
    "                                           # .columns.tolist() converte o índice de colunas em lista de nomes\n",
    "\n",
    "cat_cols = X.select_dtypes(include=['category']).columns.tolist()\n",
    "                                           # select_dtypes seleciona colunas cujo dtype é category\n",
    "                                           # .columns.tolist() converte em lista de nomes\n",
    "\n",
    "print('Numéricas:', num_cols)              # Exibe a lista de nomes de colunas numéricas\n",
    "print('Categóricas:', cat_cols)             # Exibe a lista de nomes de colunas categóricas\n",
    "\n",
    "\n",
    "# 5.2 Construir ColumnTransformer: OneHotEncoder para categóricas e StandardScaler para numéricas\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('onehot', OneHotEncoder(drop='first', sparse=False), cat_cols),\n",
    "                                           # Cria um transformador chamado 'onehot' que aplica OneHotEncoder às colunas categóricas\n",
    "                                           # drop='first' elimina uma coluna dummy para evitar multicolinearidade\n",
    "                                           # sparse=False retorna array NumPy denso em vez de matriz esparsa\n",
    "    ('scale', StandardScaler(), num_cols)    # Cria um transformador chamado 'scale' que aplica StandardScaler às colunas numéricas\n",
    "])\n",
    "                                           # ColumnTransformer combina esses dois transformadores:\n",
    "                                           #   - OneHotEncoder nas colunas listadas em cat_cols\n",
    "                                           #   - StandardScaler nas colunas listadas em num_cols\n",
    "                                           # As demais colunas (se houvesse) seriam descartadas por default (não pass-through)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7506e703",
   "metadata": {
    "id": "7506e703"
   },
   "source": [
    "Nosso preprocessor fará codificação one-hot e escalonamento padrão."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50afa566",
   "metadata": {
    "id": "50afa566"
   },
   "source": [
    "## 6. Seleção de Variáveis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72cc507",
   "metadata": {
    "id": "c72cc507"
   },
   "source": [
    "Primeiro, vamos verificar multicolinearidade com VIF. Para isso, precisamos do dataset codificado e padronizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9312923",
   "metadata": {
    "id": "e9312923"
   },
   "outputs": [],
   "source": [
    "# 6.1 Gerar matriz codificada para calcular VIF\n",
    "X_encoded = preprocessor.fit_transform(X)\n",
    "feature_names = list(preprocessor.named_transformers_['onehot'].get_feature_names_out(cat_cols)) + num_cols\n",
    "X_vif = pd.DataFrame(X_encoded, columns=feature_names)\n",
    "# Calcular VIF\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data['feature'] = feature_names\n",
    "vif_data['VIF'] = [variance_inflation_factor(X_vif.values, i) for i in range(X_vif.shape[1])]\n",
    "vif_data.sort_values(by='VIF', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PZhpU4jDpdHY",
   "metadata": {
    "id": "PZhpU4jDpdHY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f50a0984",
   "metadata": {
    "id": "f50a0984"
   },
   "source": [
    "As variáveis com VIF > 5 indicam multicolinearidade alta. Avalie remover ou combinar.\n",
    "Neste caso, `frequencia_uso_mensal` e `tempo_total_login_horas` apresentam leve correlação.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8142ee",
   "metadata": {
    "id": "5a8142ee"
   },
   "source": [
    "### 6.2 SelectKBest (Chi²)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4930e7a7",
   "metadata": {
    "id": "4930e7a7"
   },
   "outputs": [],
   "source": [
    "# Aplicar SelectKBest para selecionar as 10 variáveis mais relevantes\n",
    "selector = SelectKBest(score_func=chi2, k=10)\n",
    "X_best = selector.fit_transform(pd.DataFrame(X_encoded, columns=feature_names), y)\n",
    "best_features = np.array(feature_names)[selector.get_support()]\n",
    "print('Features selecionadas pelo SelectKBest:', best_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdb0c97",
   "metadata": {
    "id": "abdb0c97"
   },
   "source": [
    "Selecionamos as 10 variáveis que melhor se relacionam com `churn` segundo teste Chi²."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ff0079",
   "metadata": {
    "id": "a5ff0079"
   },
   "source": [
    "### 6.3 Recursive Feature Elimination (RFE) com Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe156bb5",
   "metadata": {
    "id": "fe156bb5"
   },
   "outputs": [],
   "source": [
    "# Usar RFE para selecionar 10 variáveis com base em coeficientes de regressão logística\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "rfe = RFE(estimator=lr, n_features_to_select=10)\n",
    "rfe.fit(pd.DataFrame(X_encoded, columns=feature_names), y)\n",
    "rfe_features = np.array(feature_names)[rfe.get_support()]\n",
    "print('Features selecionadas pelo RFE:', rfe_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410f61f1",
   "metadata": {
    "id": "410f61f1"
   },
   "source": [
    "Podemos comparar `SelectKBest` e `RFE` e optar pelo conjunto que gerar melhor performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e8dae8",
   "metadata": {
    "id": "30e8dae8"
   },
   "source": [
    "## 7. Divisão entre Treino e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa4d61b",
   "metadata": {
    "id": "8aa4d61b"
   },
   "outputs": [],
   "source": [
    "# Definimos o conjunto final de features (por exemplo, best_features do SelectKBest)\n",
    "X_selected = pd.DataFrame(X_encoded, columns=feature_names)[best_features]\n",
    "\n",
    "# Dividir em 80% treino e 20% teste, mantendo proporção de churn\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_selected, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print('Shape X_train:', X_train.shape)\n",
    "print('Shape X_test:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80ab503",
   "metadata": {
    "id": "c80ab503"
   },
   "source": [
    "Usamos `stratify=y` para manter a proporção de churn em treino e teste (20% de churn)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ee9d84",
   "metadata": {
    "id": "d3ee9d84"
   },
   "source": [
    "## 8. Treinamento e Avaliação de Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5657c3c6",
   "metadata": {
    "id": "5657c3c6"
   },
   "source": [
    "Treinaremos quatro modelos:\n",
    "- Regressão Logística\n",
    "- Random Forest\n",
    "- XGBoost\n",
    "- SVM (com probabilidade)\n",
    "Em seguida, compararemos as métricas (Acurácia, ROC AUC, Precision, Recall, F1-score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22320e2",
   "metadata": {
    "id": "e22320e2"
   },
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
    "}\n",
    "\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    print(f'Treinando {name}...')\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:,1]\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    results.append({\n",
    "        'Modelo': name,\n",
    "        'Accuracy': acc,\n",
    "        'ROC AUC': auc,\n",
    "        'Precision': report['1']['precision'],\n",
    "        'Recall': report['1']['recall'],\n",
    "        'F1-score': report['1']['f1-score']\n",
    "    })\n",
    "\n",
    "# DataFrame de resultados\n",
    "df_results = pd.DataFrame(results).sort_values(by='ROC AUC', ascending=False)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7365fa",
   "metadata": {
    "id": "8f7365fa"
   },
   "source": [
    "Os resultados acima permitem comparar qual modelo tem melhor desempenho para prever churn. Normalmente, priorizamos **ROC AUC** em problemas desbalanceados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8593e3c3",
   "metadata": {
    "id": "8593e3c3"
   },
   "source": [
    "## 9. Verificação de Overfitting / Underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32200bf9",
   "metadata": {
    "id": "32200bf9"
   },
   "outputs": [],
   "source": [
    "# Avaliar acurácia em treino x teste para o melhor modelo (ex.: XGBoost se for o melhor)\n",
    "best_model_name = df_results.iloc[0]['Modelo']\n",
    "best_model = models[best_model_name]\n",
    "train_acc = accuracy_score(y_train, best_model.predict(X_train))\n",
    "test_acc = accuracy_score(y_test, best_model.predict(X_test))\n",
    "print(f'Best Model: {best_model_name}')\n",
    "print(f'Train Accuracy: {train_acc:.4f}')\n",
    "print(f'Test Accuracy: {test_acc:.4f}')\n",
    "\n",
    "# Plot curva ROC treino x teste\n",
    "RocCurveDisplay.from_estimator(best_model, X_train, y_train, name='Train ROC')\n",
    "RocCurveDisplay.from_estimator(best_model, X_test, y_test, name='Test ROC', ax=plt.gca())\n",
    "plt.title(f'Curvas ROC - {best_model_name}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e50a4c5",
   "metadata": {
    "id": "6e50a4c5"
   },
   "source": [
    "Se a performance em treino for muito superior à de teste, há overfitting. Curvas ROC se sobrepondo indicam bom ajuste."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c08336e",
   "metadata": {
    "id": "6c08336e"
   },
   "source": [
    "## 10. Explainable AI (SHAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86324e5",
   "metadata": {
    "id": "c86324e5"
   },
   "source": [
    "Vamos usar SHAP para entender a contribuição de cada feature nas previsões do melhor modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32daf71",
   "metadata": {
    "id": "f32daf71"
   },
   "outputs": [],
   "source": [
    "# 10.1 Criar objeto explainer (apenas para modelos baseados em árvores, ex.: Random Forest ou XGBoost)\n",
    "import shap\n",
    "\n",
    "if best_model_name in ['Random Forest', 'XGBoost']:\n",
    "    explainer = shap.TreeExplainer(best_model)\n",
    "else:\n",
    "    explainer = shap.Explainer(best_model, X_train)\n",
    "\n",
    "# 10.2 Calcular valores SHAP para conjunto de teste\n",
    "shap_values = explainer(X_test)\n",
    "\n",
    "# 10.3 Plot summary (global)\n",
    "shap.summary_plot(shap_values, X_test, plot_type='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24385f6d",
   "metadata": {
    "id": "24385f6d"
   },
   "source": [
    "O gráfico de barras mostra a importância média de cada feature. As barras maiores indicam features mais influentes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69bf5a4",
   "metadata": {
    "id": "f69bf5a4"
   },
   "source": [
    "### 10.4 Explicação local (exemplo de um cliente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac477dc9",
   "metadata": {
    "id": "ac477dc9"
   },
   "outputs": [],
   "source": [
    "# Escolher um exemplo do conjunto de teste para explicar localmente\n",
    "idx = 5  # índice arbitrário\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value, shap_values.values[idx], X_test.iloc[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42670fe",
   "metadata": {
    "id": "b42670fe"
   },
   "source": [
    "Esse `force_plot` mostra, para um cliente específico, quais features aumentaram ou diminuíram a probabilidade de churn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c1495a",
   "metadata": {
    "id": "34c1495a"
   },
   "source": [
    "## 11. Conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9960a21d",
   "metadata": {
    "id": "9960a21d"
   },
   "source": [
    "Neste notebook, avançamos desde o pré-processamento até a construção e avaliação de múltiplos modelos, além de usar SHAP para explicar o comportamento do modelo final. Com esses passos, temos um pipeline completo para prever churn em clientes SaaS, com insights para ação e comunicação clara aos stakeholders."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
